
# In[1]:
##import libraries (basic packages)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels 

##import libraries (ML packages)
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer



# In[2]:
##Importing dataset
##WE WILL NEED TO DISCUSS WITH SHEENA HOW TO SET YOUR DIRECTORY TO PNU WOLFSON WITHIN THE PYTHON ENVIRONMENT
data = 'C:/datasets/adni_data.csv'
df = pd.read_csv(data)

##Preview dataset
df.print()

# In[3]:
##check data shape and info
df.shape         # (rows, columns)
df.columns       # Column names
df.info()        # Data types & non-null counts
df.dtypes        # Just data types


# In[4]:
##find missing data
df.isnull().sum()        # Total missing per column
df.isnull().mean()*100   # % of missing per column
df[df.isnull().any(axis=1)]  # Rows with missing values

##BASED ON THESE VALUES WE WILL DETERMINE WHETHER ANY FURTHER ACTION IS REQUIRED (e.g. dropping rows with NaN)


# In[5]:

    #LB: IN HERE YOU GO BACK TO data - do you mean df?

#Understand the visit index count (screening vs bl)
data['VISCODE'].value_counts()

#Count the number of entries per participant (RID)
data['RID'].value_counts()

    #LB: NEED TO define adni before using it as a variable

#Include only adni baseline visits 
#step 1: filter entries with VISCODE sc
adni = adni[adni['VISCODE']== 'sc' ]

#Display the data for a specific participan ID
##??
specific_participant_ID = RID12345
print(adni[adni['RID']== specific_participant_ID])



# In[6]:
## Summarise Numeric Data
df.describe()     # count, mean, std, min, max, quartiles




# In[7]
##distribution of data - baseline characteristics / identify outliers 
#histogram 
#box plot 

# LB: AT THE MOMENT YOU DEFINE DATA twice. EVEN THOUGH THIS IS A PRACISE PLEASE CAN YOU DEFINE THIS AS 'DATA_PRATCISE' AS SOMETHING DIFFERENT.
#Histograms for numeric variable distributions - using matplotlib.pylot as plt
AGE, WEIGHT, HEIGHT, BMI, BP, HR, RR, TEMP, TOTAL NE SCORE, TOTAL PE SCORE 
# Example data
data = [12, 15, 13, 17, 21, 22, 25, 30, 30, 35]

# Create histogram 
plt.hist(data, bins=5, color='skyblue', edgecolor='black')
plt.title('Histogram with Matplotlib')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.show()

#Histogram using - import seaborn as sns - matplotlib.pyplot as plt
# Create histogram
sns.histplot(data, bins=5, kde=True, color='purple')
plt.title('Histogram with Seaborn')
plt.xlabel('Value')
plt.ylabel('Count')
plt.show()
#add a smooth curve showing the data distribution

#box plot - using matplotlib.pyplot as plt

# Example data
data = [10, 15, 14, 18, 22, 25, 30, 35, 40, 60]
# Create box plot
plt.boxplot(data)
plt.title('Box Plot of Numerical Variable')
plt.ylabel('Value')
plt.show()


#Outlier detection methods for numeric variables
##Using box plot (Visual Detection)
##Using IQR (Interquartile Range) â€“ Most common method

# example data 
data = pd.DataFrame({'Age': [10, 12, 14, 16, 15, 13, 90, 11, 12, 14]})
# Calculate Q1 and Q3
Q1 = data['Age'].quantile(0.25)
Q3 = data['Age'].quantile(0.75)
IQR = Q3 - Q1
# Define bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
# Find outliers
outliers = data[(data['Age'] < lower_bound) | (data['Age'] > upper_bound)]
print("IQR Outliers:")
print(outliers)

# In[8]
#turning categorical variables into factors/numerical using import pandas as pd
# PTGENDER, PTEDUCAT, PTETHCAT, PTRACCAT, PTMARRY, APOE4

# Sample DataFrame
df = pd.DataFrame({
    'PTGENDER': ['Male', 'Female', 'Female', 'Male', 'Other']
})
# Convert to category codes
df['Gender_encoded'] = df['PTGENDER'].astype('category').cat.codes
print(df)

#LB: ONLY PTGENDER IS USED - DO YOU WANT TO HANDLE OTHER VARIABLES TOO?

# In[9]:
#Total scores for neuro and physical exams (e.g. adding up number of abnormal domains across measures)

##physical examination domains (1= normal, 2=abnormal) --> ?change to 0=normal, 1=abnormal 
#Abdomen #Back #Chest #Oedema #Extremeties #General appearance #Head, Eyes, ENT #Heart #MSK #Neck #Other #Peripheral vascular #Skin and Appendages 

df = pd.read_csv("adni_physical_examination_domains") 

# LB: YOU CANT DEFINE THE DF AGAIN AS DF AS THIS VARIABLE ALREADY HAS ONE. USE DF_PHYSICAL.
# LB: ALSO IF THIS IS A CSV THEN YOU NEED TO ADD .CSV AFTER THE FILE NAME - OTHERWISE IT IS LIKLEY TO SAY THAT IT IS NOT FOUND.

# Calculate total sum of scores
total_score = df['normal/abnormal'].sum()
print("Total Score:", total_score)

#LB: DOES THIS COLUMN EXIST - IS IS CALLED NORMAL/ABNORMAL?

##Total number of abnormal neurological examination domains 
# Load the CSV
df = pd.read_csv("adni_neurological_examination_domains") #change file name 

##LB: SAME AS BEFORE.

# Calculate total sum of scores
total_score = df['normal/abnormal'].sum()
print("Total Score:", total_score)

# In[10]:

#Making new variables based on existing ones

# In[10]: Making new variables based on existing ones

#LB; I'VE ALTERED THIS FOR YOU BELOW.

# Function to calculate BMI and interpret the result
def calculate_bmi(weight_kg, height_m):
    bmi = weight_kg / (height_m ** 2)
    print(f"BMI: {bmi:.2f}")
    if bmi < 18.5:
        print("Underweight")
    elif bmi < 25:
        print("Normal")
    elif bmi < 30:
        print("Overweight")
    else:
        print("Obesity")
    return bmi

# Function to calculate MAP (Mean Arterial Pressure)
def calculate_map(systolic, diastolic):
    map_val = (systolic + 2 * diastolic) / 3
    print(f"Mean Arterial Pressure (MAP): {map_val:.2f}")
    return map_val

#Temperature
#standardise temperature - celsius. 

#Diagnostic categories; combine MCI groups into one and combine SMC and CN into 1 controls category








